{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPP4KM0AhbU5eJBXgCsNfrA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoBRdgz/inteligencia_artificial/blob/main/transcripci%C3%B3n_autom%C3%A1tica/transcripci%C3%B3n_con_whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reconocimiento automático de voz\n",
        "\n",
        "La tarea de reconocimiento de voz, también conocida como transcripción, es capaz de convertir el lenguaje hablado (una señal de audio) en texto escrito. Conocido por sus siglas en ingles, el ASR (*Automatic Speech Recognition*) se utiliza comúnmente en aplicaciones orientadas al usuario, como agentes virtuales, generación de subtítulos en vivo, toma de notas, etc. La transcripción precisa del habla es esencial para estos casos de uso.\n",
        "\n",
        "ASR es un componente crítico de la inteligencia artificial. Se usan también terminologías alternativas para describir el reconocimiento de voz como conversión de voz a texto o STT (*speech-to-text*).\n"
      ],
      "metadata": {
        "id": "QNyQTbJCkzRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Whisper (Open AI)\n",
        "\n",
        "Whisper es un sistema de reconocimiento automático de voz (ASR) entrenado en 680,000 horas de datos supervisados multilingües y multitarea recopilados de la web. Mostramos que el uso de un conjunto de datos tan grande y diverso conduce a una mayor solidez a los acentos, el ruido de fondo y el lenguaje técnico. Además, permite la transcripción en varios idiomas, así como la traducción de esos idiomas al inglés. Somos modelos de código abierto y código de inferencia que sirven como base para crear aplicaciones útiles y para futuras investigaciones sobre procesamiento de voz sólido."
      ],
      "metadata": {
        "id": "IlUTkarQi9wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIDd6u4a3oT7",
        "outputId": "6b6d772c-8b89-4caa-d9fa-8b68dd139bae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio -q"
      ],
      "metadata": {
        "id": "OARRVfgpDdeD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradio es la forma más rápida de compartir demos su modelo de aprendizaje automático con una interfaz web amigable para que cualquiera pueda usarlo, en cualquier lugar."
      ],
      "metadata": {
        "id": "oAXKBKdt3yuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import gradio as gr\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "rHNpFsuv3uz4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"medium\")"
      ],
      "metadata": {
        "id": "Ouyo-0fZ34Nj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzdxsIYy36xH",
        "outputId": "c8f21278-c5da-4add-917b-5108dc7c1202"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe(audio):\n",
        "    \n",
        "    # Carga audio y lo rellena/recorta para que quepa en 30 segundos\n",
        "    audio = whisper.load_audio(audio)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    # Genera espectrograma log-Mel y lo comparte al mismo dispositivo que el modelo\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    # Detecta el idioma hablado\n",
        "    _, probs = model.detect_language(mel)\n",
        "    print(f\"Idioma detectado: {max(probs, key=probs.get)}\")\n",
        "\n",
        "    # Decodifica el audio\n",
        "    options = whisper.DecodingOptions()\n",
        "    result = whisper.decode(model, mel, options)\n",
        "    return result.text"
      ],
      "metadata": {
        "id": "C9ySLXCf38-5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(title='Reconocimiento automático de voz',\n",
        "             fn=transcribe,\n",
        "             description=\"Iniciar grabación con micrófono\",\n",
        "             inputs=[gr.inputs.Audio(source=\"microphone\", type=\"filepath\")],\n",
        "             outputs=\"textbox\",\n",
        "             live=True).launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "-jeIAndUCKxN",
        "outputId": "8a5ce1c7-cb1e-457d-9c22-573f1c727e16"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://9fb5bd39-10f9-4e9b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9fb5bd39-10f9-4e9b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Referencias**\n",
        "\n",
        "* https://openai.com/blog/whisper/\n",
        "* https://gradio.app/\n",
        "* https://developer.nvidia.com/blog/essential-guide-to-automatic-speech-recognition-technology/"
      ],
      "metadata": {
        "id": "ClNPpJyApU3r"
      }
    }
  ]
}