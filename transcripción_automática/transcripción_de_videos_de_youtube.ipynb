{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbnAQgGmtJYPFwNoVEk9mu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoBRdgz/inteligencia_artificial/blob/main/transcripci%C3%B3n_autom%C3%A1tica/transcripci%C3%B3n_de_videos_de_youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reconocimiento automático de voz\n",
        "\n",
        "La tarea de reconocimiento de voz, también conocida como transcripción, es capaz de convertir el lenguaje hablado (una señal de audio) en texto escrito. Conocido por sus siglas en ingles, el ASR (*Automatic Speech Recognition*) se utiliza comúnmente en aplicaciones orientadas al usuario, como agentes virtuales, generación de subtítulos en vivo, toma de notas, etc. La transcripción precisa del habla es esencial para estos casos de uso.\n",
        "\n",
        "ASR es un componente crítico de la inteligencia artificial. Se usan también terminologías alternativas para describir el reconocimiento de voz como conversión de voz a texto o STT (*speech-to-text*)."
      ],
      "metadata": {
        "id": "kHM40RhU9Pye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Whisper (Open AI)\n",
        "\n",
        "Whisper es un sistema de reconocimiento automático de voz (ASR) entrenado en 680,000 horas de datos supervisados multilingües y multitarea recopilados de la web. Mostramos que el uso de un conjunto de datos tan grande y diverso conduce a una mayor solidez a los acentos, el ruido de fondo y el lenguaje técnico. Además, permite la transcripción en varios idiomas, así como la traducción de esos idiomas al inglés. Somos modelos de código abierto y código de inferencia que sirven como base para crear aplicaciones útiles y para futuras investigaciones sobre procesamiento de voz sólido."
      ],
      "metadata": {
        "id": "GjMc75GH9VfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "fCDw8S0l-zc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git "
      ],
      "metadata": {
        "id": "vEC7NMFe_Xzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube"
      ],
      "metadata": {
        "id": "U12NJExc_1fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqGaw0otAgZK",
        "outputId": "0595668b-ed76-4156-b522-408cbf114cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Feb 18 00:45:50 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P0    28W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import gradio as gr\n",
        "from pytube import YouTube"
      ],
      "metadata": {
        "id": "_M0dAqS--VIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "xmRYdQb0-SFv",
        "outputId": "42b13632-a980-4ac0-b3b3-c91ae35423b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://a8be6c34-8609-4845.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a8be6c34-8609-4845.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "class GradioInference():\n",
        "  def __init__(self):\n",
        "    self.sizes = list(whisper._MODELS.keys())\n",
        "    self.langs = [\"none\"] + sorted(list(whisper.tokenizer.LANGUAGES.values()))\n",
        "    self.current_size = \"base\"\n",
        "    self.loaded_model = whisper.load_model(self.current_size)\n",
        "    self.yt = None\n",
        "  \n",
        "  def __call__(self, link, lang, size, subs):\n",
        "    if self.yt is None:\n",
        "      self.yt = YouTube(link)\n",
        "    path = self.yt.streams.filter(only_audio=True)[0].download(filename=\"tmp.mp4\")\n",
        "\n",
        "    if lang == \"none\":\n",
        "      lang = None\n",
        "\n",
        "    if size != self.current_size:\n",
        "      self.loaded_model = whisper.load_model(size)\n",
        "      self.current_size = size\n",
        "    results = self.loaded_model.transcribe(path, language=lang)\n",
        "\n",
        "    if subs == \"None\":\n",
        "      return results[\"text\"]\n",
        "    elif subs == \".srt\":\n",
        "      return self.srt(results[\"segments\"])\n",
        "    elif \".csv\" == \".csv\":\n",
        "      return self.csv(results[\"segments\"])\n",
        "   \n",
        "  def srt(self, segments):\n",
        "    output = \"\"\n",
        "    for i, segment in enumerate(segments):\n",
        "      output += f\"{i+1}\\n\"\n",
        "      output += f\"{self.format_time(segment['start'])} --> {self.format_time(segment['end'])}\\n\"\n",
        "      output += f\"{segment['text']}\\n\\n\"\n",
        "    return output\n",
        "  \n",
        "  def csv(self, segments):\n",
        "    output = \"\"\n",
        "    for segment in segments:\n",
        "      output += f\"{segment['start']},{segment['end']},{segment['text']}\\n\"\n",
        "    return output\n",
        "\n",
        "  def format_time(self, time):\n",
        "    hours = time//3600\n",
        "    minutes = (time - hours*3600)//60\n",
        "    seconds = time - hours*3600 - minutes*60\n",
        "    milliseconds = (time - int(time))*1000\n",
        "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{int(milliseconds):03d}\"\n",
        "    \n",
        "  def populate_metadata(self, link):\n",
        "    self.yt = YouTube(link)\n",
        "    return self.yt.thumbnail_url, self.yt.title\n",
        "\n",
        "gio = GradioInference()\n",
        "title=\"Transcripción de videos de YouTube\"\n",
        "description=\"Transcripción de voz a texto de videos de Youtube utilizando Whisper de OpenAI\"\n",
        "\n",
        "block = gr.Blocks()\n",
        "with block:\n",
        "    gr.HTML(\n",
        "        \"\"\"\n",
        "            <div style=\"text-align: center; max-width: 500px; margin: 0 auto;\">\n",
        "              <div>\n",
        "                <h1>Transcripción de videos de YouTube</h1>\n",
        "              </div>\n",
        "              <p style=\"margin-bottom: 10px; font-size: 94%\">\n",
        "                Transcripción de voz a texto de videos de Youtube utilizando Whisper de OpenAI\n",
        "              </p>\n",
        "            </div>\n",
        "        \"\"\"\n",
        "    )\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "          with gr.Row().style(equal_height=True):\n",
        "            sz = gr.Dropdown(label=\"Tamaño del Modelo\", choices=gio.sizes, value='base')\n",
        "            lang = gr.Dropdown(label=\"Idioma (Opcional)\", choices=gio.langs, value=\"none\")\n",
        "          with gr.Row().style(equal_height=True):\n",
        "            wt = gr.Radio([\"No\", \".srt\", \".csv\"], label=\"¿Con marcas de tiempo?\")\n",
        "          link = gr.Textbox(label=\"Enlace a YouTube\")\n",
        "          title = gr.Label(label=\"Título del Video\")\n",
        "          with gr.Row().style(equal_height=True):\n",
        "            img = gr.Image(label=\"Miniatura\")\n",
        "            text = gr.Textbox(label=\"Transcripción\", placeholder=\"Salida de la Transcripción\", lines=10)\n",
        "          with gr.Row().style(equal_height=True): \n",
        "              btn = gr.Button(\"Transcribir\")\n",
        "          btn.click(gio, inputs=[link, lang, sz, wt], outputs=[text])\n",
        "          link.change(gio.populate_metadata, inputs=[link], outputs=[img, title])\n",
        "block.launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Referencias**\n",
        "\n",
        "* https://gradio.app/\n",
        "* https://openai.com/blog/whisper/\n",
        "* https://dev.to/zirkelc/automatically-transcribe-youtube-videos-with-openai-whisper-1856"
      ],
      "metadata": {
        "id": "0A_laZeFnVF_"
      }
    }
  ]
}