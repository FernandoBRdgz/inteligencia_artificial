{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPTcvx5gxd3y1KJxo7OHZAL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoBRdgz/inteligencia_artificial/blob/main/incrustaciones_de_palabras/word2vec_yelp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introducción\n",
        "\n",
        "El conjunto de datos de Yelp es un subconjunto de nuestros negocios, reseñas y datos de usuario para su uso con fines personales, educativos y académicos. Disponible como archivos JSON, úselo para enseñar a los estudiantes acerca de las bases de datos, para aprender NLP o para obtener datos de producción de muestra mientras aprende a crear aplicaciones móviles.\n",
        "\n",
        "Enlace al conjunto de datos: https://www.kaggle.com/datasets/yelp-dataset/yelp-dataset"
      ],
      "metadata": {
        "id": "da3gt9aJTR8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3aGrXdCRym3",
        "outputId": "4aabf0d3-cc27-4632-db9c-db2def17421b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "xjsnVrfIR-YD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_path = '/content/drive/MyDrive/'"
      ],
      "metadata": {
        "id": "hzSyWvyaR_pr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = os.path.join(main_path, 'data', 'yelp_dataset')"
      ],
      "metadata": {
        "id": "t4XtWhEHSgIj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "businesses_filepath = os.path.join(data_directory, 'yelp_academic_dataset_business.json')"
      ],
      "metadata": {
        "id": "1xPPxy6HShn3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mkh5zqfTPbt0",
        "outputId": "f99c8719-fec9-4ac7-8cea-724d55d4cf22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('{\"business_id\":\"Pns2l4eNsfO8kk83dixA6A\",\"name\":\"Abby Rappoport, LAC, '\n",
            " 'CMQ\",\"address\":\"1616 Chapala St, Ste 2\",\"city\":\"Santa '\n",
            " 'Barbara\",\"state\":\"CA\",\"postal_code\":\"93101\",\"latitude\":34.4266787,\"longitude\":-119.7111968,\"stars\":5.0,\"review_count\":7,\"is_open\":0,\"attributes\":{\"ByAppointmentOnly\":\"True\"},\"categories\":\"Doctors, '\n",
            " 'Traditional Chinese Medicine, Naturopathic\\\\/Holistic, Acupuncture, Health & '\n",
            " 'Medical, Nutritionists\",\"hours\":null}\\n')\n"
          ]
        }
      ],
      "source": [
        "with open(businesses_filepath) as f:\n",
        "    first_business_record = f.readline() \n",
        "\n",
        "pprint(first_business_record)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_json_filepath = os.path.join(data_directory, 'yelp_academic_dataset_review.json')"
      ],
      "metadata": {
        "id": "0SPGh3uUVBac"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(review_json_filepath) as f:\n",
        "    first_review_record = f.readline()\n",
        "    \n",
        "pprint(first_review_record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6pAhgvSSilq",
        "outputId": "6a3ad5d7-401d-4c49-9030-a53d6313f3dc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('{\"review_id\":\"KU_O5udG6zpxOg-VcAEodg\",\"user_id\":\"mh_-eMZ6K5RLWhZyISBhwA\",\"business_id\":\"XQfwVwDr-v0ZS3_CbbE5Xw\",\"stars\":3.0,\"useful\":0,\"funny\":0,\"cool\":0,\"text\":\"If '\n",
            " 'you decide to eat here, just be aware it is going to take about 2 hours from '\n",
            " 'beginning to end. We have tried it multiple times, because I want to like '\n",
            " \"it! I have been to it's other locations in NJ and never had a bad \"\n",
            " 'experience. \\\\n\\\\nThe food is good, but it takes a very long time to come '\n",
            " 'out. The waitstaff is very young, but usually pleasant. We have just had too '\n",
            " 'many experiences where we spent way too long waiting. We usually opt for '\n",
            " 'another diner or restaurant on the weekends, in order to be done '\n",
            " 'quicker.\",\"date\":\"2018-07-07 22:09:11\"}\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_ids = set()\n",
        "\n",
        "with open(businesses_filepath) as f:    \n",
        "    for business_json in f:\n",
        "        business = json.loads(business_json)\n",
        "        if not business.get('categories'):\n",
        "            continue\n",
        "        if 'Restaurants' not in business['categories']:\n",
        "            continue\n",
        "        restaurant_ids.add(business['business_id'])\n",
        "\n",
        "restaurant_ids = frozenset(restaurant_ids)\n",
        "\n",
        "pprint(f'{len(restaurant_ids):,} restaurants in the dataset.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BciTv5xFVFF2",
        "outputId": "bc0a2d5f-e98e-44cd-cb40-b29bf5e28cae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'52,268 restaurants in the dataset.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scratch_directory = os.path.join(data_directory, 'scratch')\n",
        "\n",
        "try:\n",
        "    os.mkdir(scratch_directory)\n",
        "except FileExistsError:\n",
        "    pass\n",
        "\n",
        "review_txt_filepath = os.path.join(scratch_directory, 'review_text_all.txt')"
      ],
      "metadata": {
        "id": "M2GnvlOAVbph"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "execute = False\n",
        "\n",
        "if execute:\n",
        "    review_count = 0\n",
        "    with open(review_txt_filepath, 'w') as review_txt_file:\n",
        "        with open(review_json_filepath) as review_json_file:\n",
        "            for review_json in review_json_file:\n",
        "                review = json.loads(review_json)\n",
        "                if review['business_id'] not in restaurant_ids:\n",
        "                    continue\n",
        "                review_txt_file.write(review['text'].replace('\\n', '\\\\n') + '\\n')\n",
        "                review_count += 1\n",
        "    print(f'Text from {review_count:,} restaurant reviews written to the new txt file.')\n",
        "    \n",
        "else:\n",
        "    with open(review_txt_filepath) as review_txt_file:\n",
        "        for review_count, line in enumerate(review_txt_file):\n",
        "            pass\n",
        "        \n",
        "    print(f'Text from {review_count + 1:,} restaurant reviews in the txt file.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFC_H3xEVs_G",
        "outputId": "376c4be0-6f1a-4fe6-f262-4f201db53f98"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text from 4,725,884 restaurant reviews in the txt file.\n",
            "CPU times: user 8.53 s, sys: 1.65 s, total: 10.2 s\n",
            "Wall time: 47.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import pandas as pd\n",
        "import itertools as it"
      ],
      "metadata": {
        "id": "9yYRUPI2052x"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7Pl02Eu1drE",
        "outputId": "9066ecd2-6c24-4669-f046-80229c92ff57"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-12 18:56:50.958187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.2)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_md')"
      ],
      "metadata": {
        "id": "8dd5N-2E07rv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_num = 42\n",
        "\n",
        "with open(review_txt_filepath) as f:\n",
        "    sample_review = list(it.islice(f, review_num, review_num+1))[0]\n",
        "    sample_review = sample_review.replace('\\\\n', '\\n')\n",
        "        \n",
        "print(sample_review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEmslJt112ck",
        "outputId": "e9b78f88-8032-4f17-84eb-c959d793153b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excellent service! Great diner food and breakfast is served all day. Came here for lunch- they were busy but very friendly and hospitable. Easy to get to off the 295.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "parsed_review = nlp(sample_review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxuOqRWc2Tn7",
        "outputId": "98dc4776-248f-4dad-9782-96d5fc4bcc82"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 27.5 ms, sys: 2.71 ms, total: 30.2 ms\n",
            "Wall time: 80.5 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(parsed_review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9bBtStv2ZLk",
        "outputId": "48350ab9-94c8-47ab-84e8-8956ac2dd777"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excellent service! Great diner food and breakfast is served all day. Came here for lunch- they were busy but very friendly and hospitable. Easy to get to off the 295.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(parsed_review, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "l3DJVlZg2lMm",
        "outputId": "b3a7b7de-b027-4afe-b742-abf889d3db34"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Excellent service! Great diner food and breakfast is served \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    all day\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". Came here for lunch- they were busy but very friendly and hospitable. Easy to get to off the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    295\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              ".</br></div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from gensim.models.word2vec import LineSentence"
      ],
      "metadata": {
        "id": "8Ggq42Ch6BnG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def punct_space(token):\n",
        "    return token.is_punct or token.is_space\n",
        "\n",
        "def pronoun_lemmatize(token):\n",
        "    if token.lemma_ == '-PRON-':\n",
        "        return token.lower_\n",
        "    \n",
        "    else:\n",
        "        return token.lemma_.lower()\n",
        "\n",
        "def line_review(filename):\n",
        "    with open(filename) as f:\n",
        "        for review in f:\n",
        "            yield review.replace('\\\\n', '\\n')"
      ],
      "metadata": {
        "id": "fchScF996U-j"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_lemmatized_filepath = os.path.join(scratch_directory, 'review_lemmatized_all.txt')\n",
        "sentence_lemmatized_filepath = os.path.join(scratch_directory, 'sentence_lemmatized_all.txt')"
      ],
      "metadata": {
        "id": "BWmDFwDs6ovk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "execute = False\n",
        "\n",
        "if execute:\n",
        "    with open(review_lemmatized_filepath, 'w') as review_file:\n",
        "        with open(sentence_lemmatized_filepath, 'w') as sentence_file:\n",
        "            pipe = nlp.pipe(\n",
        "                line_review(review_txt_filepath),\n",
        "                batch_size=5000\n",
        "                )\n",
        "            \n",
        "            for parsed_review in pipe:\n",
        "                lemmatized_review = ' '.join([\n",
        "                    pronoun_lemmatize(token)\n",
        "                    for token in parsed_review\n",
        "                    if not punct_space(token)\n",
        "                    ])\n",
        "                \n",
        "                review_file.write(lemmatized_review + '\\n')\n",
        "        \n",
        "                for sent in parsed_review.sents:\n",
        "                    lemmatized_sentence = ' '.join([\n",
        "                        pronoun_lemmatize(token)\n",
        "                        for token in sent\n",
        "                        if not punct_space(token)\n",
        "                        ])\n",
        "                    \n",
        "                    sentence_file.write(lemmatized_sentence + '\\n')"
      ],
      "metadata": {
        "id": "0Vrh0J-M6vc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd6bd993-42bf-471d-ef1d-2fbdb49272aa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
            "Wall time: 10.7 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_unigrams = LineSentence(sentence_lemmatized_filepath)"
      ],
      "metadata": {
        "id": "2q7wDjjcgE4Z"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence_unigrams in it.islice(sentences_unigrams, 60, 70):\n",
        "    print(' '.join(sentence_unigrams))\n",
        "    print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07D4jzZQgHM3",
        "outputId": "2a737500-68d6-4311-f34d-728e1c85f4bc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bun make the sonoran dog\n",
            "\n",
            "it be like a snuggie for the pup\n",
            "\n",
            "a first it seem ridiculous and almost like it be go to be too much exactly like everyone 's favorite blanket with sleeve\n",
            "\n",
            "too much softness too much smush too indulgent\n",
            "\n",
            "wrong\n",
            "\n",
            "it be warm soft chewy fragrant and it succeed where other famed sonoran dogs fail\n",
            "\n",
            "the hot dog itself be flavorful but i would prefer that it or the bacon have a little more bite or snap to well hold their own against the dominant mustard and onion\n",
            "\n",
            "i be with the masse on the carne asada caramelo\n",
            "\n",
            "excellent tortilla salty melty cheese and great carne\n",
            "\n",
            "super cheap and you can drive through\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_model_filepath = os.path.join(scratch_directory, 'bigram_phrase_model')"
      ],
      "metadata": {
        "id": "8CYl_hdwWPD7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "execute = False\n",
        "\n",
        "if execute:\n",
        "\n",
        "    bigram_phrases = Phrases(sentences_unigrams)\n",
        "    bigram_phrases = Phraser(bigram_phrases)\n",
        "    bigram_phrases.save(bigram_model_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0k_JSmfWUdi",
        "outputId": "17d3092d-d431-4cee-d30a-0b1cac606fe0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
            "Wall time: 9.06 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_phrases = Phraser.load(bigram_model_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD_23AzBWgAM",
        "outputId": "6ce03e6f-2ba7-4c25-9468-6d7911266f61"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.phrases:older version of FrozenPhrases loaded without corpus_word_count\n",
            "WARNING:gensim.models.phrases:setting corpus_word_count to 0, do not use it in your scoring function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_bigrams_filepath = os.path.join(scratch_directory, 'sentence_bigram_phrases_all.txt')"
      ],
      "metadata": {
        "id": "HxMnQIX8XTwq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "execute = False\n",
        "if execute:\n",
        "    with open(sentences_bigrams_filepath, 'w') as f:\n",
        "        for sentence_unigrams in sentences_unigrams:\n",
        "            sentence_bigrams = ' '.join(bigram_phrases[sentence_unigrams])\n",
        "            f.write(sentence_bigrams + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQBJJsK_XTfz",
        "outputId": "a66daa66-8dac-4901-ee79-2375468357d3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.2 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_bigrams = LineSentence(sentences_bigrams_filepath)"
      ],
      "metadata": {
        "id": "tWlC56gIXhb4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence_bigrams in it.islice(sentences_bigrams, 60, 70):\n",
        "    print(' '.join(sentence_bigrams))\n",
        "    print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsgvZpPbZanO",
        "outputId": "95ca201e-c6ed-4040-d1f2-5f624eea42ee"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bun make the sonoran_dog\n",
            "\n",
            "it be like a snuggie for the pup\n",
            "\n",
            "a first it seem ridiculous and almost like it be go to be too much exactly like everyone 's favorite blanket with sleeve\n",
            "\n",
            "too much softness too much smush too indulgent\n",
            "\n",
            "wrong\n",
            "\n",
            "it be warm soft chewy fragrant and it succeed where other famed sonoran_dogs fail\n",
            "\n",
            "the hot_dog itself be flavorful but i would prefer that it or the bacon have a little more bite or snap to well hold their own against the dominant mustard and onion\n",
            "\n",
            "i be with the masse on the carne_asada caramelo\n",
            "\n",
            "excellent tortilla salty melty_cheese and great carne\n",
            "\n",
            "super cheap and you can drive_through\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_model_filepath = os.path.join(scratch_directory, 'trigram_phrase_model')"
      ],
      "metadata": {
        "id": "DUM4HdVFZhf5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "execute = False\n",
        "\n",
        "if execute:\n",
        "\n",
        "    trigram_phrases = Phrases(sentences_bigrams)\n",
        "    trigram_phrases = Phraser(trigram_phrases)\n",
        "    trigram_phrases.save(trigram_model_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4FaYmNjZj_T",
        "outputId": "141fe317-b938-455e-f27e-bafcd565a09e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 9.3 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_phrases = Phraser.load(trigram_model_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW-EMxpYZpxd",
        "outputId": "fd8a77bc-561a-4542-f6ab-7ebdbf519ede"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.phrases:older version of FrozenPhrases loaded without corpus_word_count\n",
            "WARNING:gensim.models.phrases:setting corpus_word_count to 0, do not use it in your scoring function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_trigrams_filepath = os.path.join(scratch_directory, 'sentence_trigram_phrases_all.txt')"
      ],
      "metadata": {
        "id": "RTdM18RkZpt5"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "execute = False\n",
        "\n",
        "if execute:\n",
        "    with open(sentences_trigrams_filepath, 'w') as f:\n",
        "        for sentence_bigrams in sentences_bigrams:\n",
        "            sentence_trigrams = ' '.join(trigram_phrases[sentence_bigrams])\n",
        "            f.write(sentence_trigrams + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEVC1Xt9Z6Oo",
        "outputId": "f0bfd7f2-a0d2-4778-fc06-a4b5a4dcbff1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6 µs, sys: 1e+03 ns, total: 7 µs\n",
            "Wall time: 11 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_trigrams = LineSentence(sentences_trigrams_filepath)"
      ],
      "metadata": {
        "id": "LCk86gtvZ58O"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence_trigrams in it.islice(sentences_trigrams, 60, 70):\n",
        "    print(' '.join(sentence_trigrams))\n",
        "    print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPDwwRS8aD2v",
        "outputId": "59e3278a-0b9c-4505-b9fa-ff46f80a39fd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bun make the sonoran_dog\n",
            "\n",
            "it be like a snuggie for the pup\n",
            "\n",
            "a first it seem ridiculous and almost like it be go to be too much exactly like everyone 's favorite blanket with sleeve\n",
            "\n",
            "too much softness too much smush too indulgent\n",
            "\n",
            "wrong\n",
            "\n",
            "it be warm soft chewy fragrant and it succeed where other famed sonoran_dogs fail\n",
            "\n",
            "the hot_dog itself be flavorful but i would prefer that it or the bacon have a little more bite or snap to well hold their own against the dominant mustard and onion\n",
            "\n",
            "i be with the masse on the carne_asada_caramelo\n",
            "\n",
            "excellent tortilla salty melty_cheese and great carne\n",
            "\n",
            "super cheap and you can drive_through\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_trigrams_filepath = os.path.join(scratch_directory, 'review_trigrams_all.txt')"
      ],
      "metadata": {
        "id": "SUVhg9pkaDmX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "execute = False\n",
        "\n",
        "if execute:\n",
        "    reviews_lemmatized = LineSentence(review_lemmatized_filepath)\n",
        "\n",
        "    with open(review_trigrams_filepath, 'w') as f:\n",
        "        \n",
        "        for review_unigrams in reviews_lemmatized:\n",
        "            review_bigrams = bigram_phrases[review_unigrams]\n",
        "            review_trigrams = trigram_phrases[review_bigrams]\n",
        "\n",
        "            review_trigrams = [\n",
        "                term\n",
        "                for term in review_trigrams\n",
        "                if term not in nlp.Defaults.stop_words\n",
        "                ]\n",
        "\n",
        "            review_trigrams = ' '.join(review_trigrams)\n",
        "            f.write(review_trigrams + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2j6KA-OaHkr",
        "outputId": "9de34279-abb8-42a7-8d42-402348b3e9d5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
            "Wall time: 10.3 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_num = 0\n",
        "\n",
        "print('Original:' + '\\n')\n",
        "\n",
        "for review in it.islice(line_review(review_txt_filepath), review_num, review_num+1):\n",
        "    print(review)\n",
        "\n",
        "print('----' + '\\n')\n",
        "print('Transformed:' + '\\n')\n",
        "\n",
        "with open(review_trigrams_filepath) as f:\n",
        "    for review in it.islice(f, review_num, review_num+1):\n",
        "        print(review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CPrb4iAaMrc",
        "outputId": "654374a7-17f3-429c-fd94-0fd2bd98665d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:\n",
            "\n",
            "If you decide to eat here, just be aware it is going to take about 2 hours from beginning to end. We have tried it multiple times, because I want to like it! I have been to it's other locations in NJ and never had a bad experience. \n",
            "\n",
            "The food is good, but it takes a very long time to come out. The waitstaff is very young, but usually pleasant. We have just had too many experiences where we spent way too long waiting. We usually opt for another diner or restaurant on the weekends, in order to be done quicker.\n",
            "\n",
            "----\n",
            "\n",
            "Transformed:\n",
            "\n",
            "decide eat aware 2 hour begin end try multiple time want like location nj bad experience food good long time come waitstaff young usually pleasant experience spend way long wait usually opt diner restaurant weekend order quick\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "id": "62Ix2NRSU9OH",
        "outputId": "b6a9890c-57c8-4608-9a6a-6768eb541e5b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.24.2 (from pyLDAvis)\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.10.1)\n",
            "Collecting pandas>=2.0.0 (from pyLDAvis)\n",
            "  Downloading pandas-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.8.4)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2022.7.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.1.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (6.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (2.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
            "Installing collected packages: funcy, numpy, pandas, pyLDAvis\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.5.3, but you have pandas 2.0.1 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed funcy-2.0 numpy-1.24.3 pandas-2.0.1 pyLDAvis-3.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.corpora import Dictionary, MmCorpus\n",
        "from gensim.models.ldamulticore import LdaMulticore\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim\n",
        "import warnings\n",
        "import pickle"
      ],
      "metadata": {
        "id": "0T5O7zxAU0mE"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary_filepath = os.path.join(scratch_directory, 'trigram_dict_all.dict')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BuZEQa3VK03",
        "outputId": "b9652686-ec12-4ac9-cf55-84abefb51cce"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "execute = False\n",
        "\n",
        "if execute:\n",
        "    reviews_trigrams = LineSentence(review_trigrams_filepath)\n",
        "    dictionary_trigrams = Dictionary(reviews_trigrams)\n",
        "    dictionary_trigrams.filter_extremes(no_below=20, no_above=0.4)\n",
        "    dictionary_trigrams.compactify()\n",
        "    dictionary_trigrams.save(dictionary_filepath)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH1_3yKsVNiM",
        "outputId": "950acade-541c-4896-9eac-ad6d5070a981"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 30.9 s, sys: 220 ms, total: 31.1 s\n",
            "Wall time: 32.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary_trigrams = Dictionary.load(dictionary_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCue4KeEWITd",
        "outputId": "3a20bb48-861c-49a5-ff06-22495861c8d8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow_corpus_filepath = os.path.join(scratch_directory, 'bow_trigrams_corpus_all.mm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAWzpJIvWN18",
        "outputId": "53c22823-877c-4821-f42f-9f87471ac9b9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bow_generator(filepath):\n",
        "   \n",
        "    for review in LineSentence(filepath):\n",
        "        yield dictionary_trigrams.doc2bow(review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYOWcYmXWQHN",
        "outputId": "ca9ef80f-3edf-429a-deac-622adb551a0d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "execute = False\n",
        "\n",
        "if execute:\n",
        "    MmCorpus.serialize(bow_corpus_filepath, bow_generator(review_trigrams_filepath))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpCBPAxkWVWI",
        "outputId": "5705dc29-8fe3-46e6-f1a2-fe628aa2a56f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 37.7 s, sys: 1.12 s, total: 38.9 s\n",
            "Wall time: 41.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_bow_corpus = MmCorpus(bow_corpus_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa0hDGqVXViJ",
        "outputId": "29df6737-95e3-4e88-9a4c-f5cb405c2dda"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model_filepath = os.path.join(scratch_directory, 'lda_model_all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_8toQmDXXqt",
        "outputId": "fbaf491e-3f54-41bf-df92-8e9b37dcca67"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "execute = False\n",
        "\n",
        "if execute:\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter('ignore')\n",
        "        lda = LdaMulticore(trigram_bow_corpus, num_topics=50, id2word=dictionary_trigrams, workers=7)\n",
        "    \n",
        "    lda.save(lda_model_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1s645atXbGt",
        "outputId": "176d430b-1a36-43f2-816c-0af28f307740"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 29s, sys: 6.96 s, total: 1min 36s\n",
            "Wall time: 7min 38s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LdaMulticore.load(lda_model_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8eprIBlXnWB",
        "outputId": "4f26d569-4be3-4eb6-da98-3f9deba0a1cb"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def explore_topic(topic_number, topn=25):\n",
        "    print(f'{\"term\":20} {\"frequency\"}' + '\\n')\n",
        "\n",
        "    for term, frequency in lda.show_topic(topic_number, topn=25):\n",
        "        print(f'{term:20} {round(frequency, 3):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEKeFThHXp37",
        "outputId": "b953d531-7e16-4e50-8b42-02f12f728654"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "explore_topic(topic_number=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCrDQf-vXto7",
        "outputId": "94821f1c-817b-461f-957a-42b53d3a942f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "term                 frequency\n",
            "\n",
            "place                0.033\n",
            "like                 0.025\n",
            "lunch                0.016\n",
            "menu                 0.014\n",
            "nice                 0.010\n",
            "time                 0.010\n",
            "lot                  0.009\n",
            "come                 0.009\n",
            "look                 0.009\n",
            "service              0.009\n",
            "great                0.008\n",
            "friendly             0.008\n",
            "option               0.008\n",
            "chipotle             0.008\n",
            "pretty               0.008\n",
            "definitely           0.007\n",
            "day                  0.007\n",
            "sub                  0.007\n",
            "clean                0.007\n",
            "try                  0.007\n",
            "work                 0.006\n",
            "order                0.006\n",
            "feel                 0.006\n",
            "bit                  0.005\n",
            "quick                0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Por hacer**\n",
        "\n",
        "* Añadir comentarios\n",
        "* Incrustaciones de palabra con Word2vec\n",
        "* Visualizaciones\n",
        "* Perfilamiento de tópicos\n",
        "* Álgebra de palabras"
      ],
      "metadata": {
        "id": "pq0aqfH1YqAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Referencias**\n",
        "\n",
        "* https://spacy.io/\n",
        "* https://radimrehurek.com/gensim/\n",
        "* https://github.com/pwharrison/modern-nlp-in-python-2019/blob/master/notebooks/Modern_NLP_in_Python.ipynb"
      ],
      "metadata": {
        "id": "QClEkJKWaKpp"
      }
    }
  ]
}