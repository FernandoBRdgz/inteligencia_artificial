{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOCmTqdkB/DjHo+R1Ttnb7a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoBRdgz/inteligencia_artificial/blob/main/incrustaciones_de_palabras/word2vec_yelp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introducción\n",
        "\n",
        "El conjunto de datos de Yelp es un subconjunto de nuestros negocios, reseñas y datos de usuario para su uso con fines personales, educativos y académicos. Disponible como archivos JSON, úselo para enseñar a los estudiantes acerca de las bases de datos, para aprender NLP o para obtener datos de producción de muestra mientras aprende a crear aplicaciones móviles.\n",
        "\n",
        "Enlace al conjunto de datos: https://www.kaggle.com/datasets/yelp-dataset/yelp-dataset"
      ],
      "metadata": {
        "id": "da3gt9aJTR8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3aGrXdCRym3",
        "outputId": "457461b3-0fcf-43c4-fe9a-b39c71ede987"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "xjsnVrfIR-YD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_path = '/content/drive/MyDrive/'"
      ],
      "metadata": {
        "id": "hzSyWvyaR_pr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = os.path.join(main_path, 'data', 'yelp_dataset')"
      ],
      "metadata": {
        "id": "t4XtWhEHSgIj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "businesses_filepath = os.path.join(data_directory, 'yelp_academic_dataset_business.json')"
      ],
      "metadata": {
        "id": "1xPPxy6HShn3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mkh5zqfTPbt0",
        "outputId": "ce12e982-fa44-411c-9f27-a523f506b145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('{\"business_id\":\"Pns2l4eNsfO8kk83dixA6A\",\"name\":\"Abby Rappoport, LAC, '\n",
            " 'CMQ\",\"address\":\"1616 Chapala St, Ste 2\",\"city\":\"Santa '\n",
            " 'Barbara\",\"state\":\"CA\",\"postal_code\":\"93101\",\"latitude\":34.4266787,\"longitude\":-119.7111968,\"stars\":5.0,\"review_count\":7,\"is_open\":0,\"attributes\":{\"ByAppointmentOnly\":\"True\"},\"categories\":\"Doctors, '\n",
            " 'Traditional Chinese Medicine, Naturopathic\\\\/Holistic, Acupuncture, Health & '\n",
            " 'Medical, Nutritionists\",\"hours\":null}\\n')\n"
          ]
        }
      ],
      "source": [
        "with open(businesses_filepath) as f:\n",
        "    first_business_record = f.readline() \n",
        "\n",
        "pprint(first_business_record)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_json_filepath = os.path.join(data_directory, 'yelp_academic_dataset_review.json')"
      ],
      "metadata": {
        "id": "0SPGh3uUVBac"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(review_json_filepath) as f:\n",
        "    first_review_record = f.readline()\n",
        "    \n",
        "pprint(first_review_record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6pAhgvSSilq",
        "outputId": "47701a1b-b769-46b7-b73a-d4053639579c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('{\"review_id\":\"KU_O5udG6zpxOg-VcAEodg\",\"user_id\":\"mh_-eMZ6K5RLWhZyISBhwA\",\"business_id\":\"XQfwVwDr-v0ZS3_CbbE5Xw\",\"stars\":3.0,\"useful\":0,\"funny\":0,\"cool\":0,\"text\":\"If '\n",
            " 'you decide to eat here, just be aware it is going to take about 2 hours from '\n",
            " 'beginning to end. We have tried it multiple times, because I want to like '\n",
            " \"it! I have been to it's other locations in NJ and never had a bad \"\n",
            " 'experience. \\\\n\\\\nThe food is good, but it takes a very long time to come '\n",
            " 'out. The waitstaff is very young, but usually pleasant. We have just had too '\n",
            " 'many experiences where we spent way too long waiting. We usually opt for '\n",
            " 'another diner or restaurant on the weekends, in order to be done '\n",
            " 'quicker.\",\"date\":\"2018-07-07 22:09:11\"}\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_ids = set()\n",
        "\n",
        "with open(businesses_filepath) as f:    \n",
        "    for business_json in f:\n",
        "        business = json.loads(business_json)\n",
        "        if not business.get('categories'):\n",
        "            continue\n",
        "        if 'Restaurants' not in business['categories']:\n",
        "            continue\n",
        "        restaurant_ids.add(business['business_id'])\n",
        "\n",
        "restaurant_ids = frozenset(restaurant_ids)\n",
        "\n",
        "pprint(f'{len(restaurant_ids):,} restaurants in the dataset.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BciTv5xFVFF2",
        "outputId": "9cebec69-9033-4a21-ed9f-91d86c449562"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'52,268 restaurants in the dataset.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scratch_directory = os.path.join(data_directory, 'scratch')\n",
        "\n",
        "try:\n",
        "    os.mkdir(scratch_directory)\n",
        "except FileExistsError:\n",
        "    pass\n",
        "\n",
        "review_txt_filepath = os.path.join(scratch_directory, 'review_text_all.txt')"
      ],
      "metadata": {
        "id": "M2GnvlOAVbph"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "execute = False\n",
        "\n",
        "if execute:\n",
        "    review_count = 0\n",
        "    with open(review_txt_filepath, 'w') as review_txt_file:\n",
        "        with open(review_json_filepath) as review_json_file:\n",
        "            for review_json in review_json_file:\n",
        "                review = json.loads(review_json)\n",
        "                if review['business_id'] not in restaurant_ids:\n",
        "                    continue\n",
        "                review_txt_file.write(review['text'].replace('\\n', '\\\\n') + '\\n')\n",
        "                review_count += 1\n",
        "    print(f'Text from {review_count:,} restaurant reviews written to the new txt file.')\n",
        "    \n",
        "else:\n",
        "    with open(review_txt_filepath) as review_txt_file:\n",
        "        for review_count, line in enumerate(review_txt_file):\n",
        "            pass\n",
        "        \n",
        "    print(f'Text from {review_count + 1:,} restaurant reviews in the txt file.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFC_H3xEVs_G",
        "outputId": "38a65c90-391f-417c-81a2-02689f8cebd1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text from 4,725,884 restaurant reviews in the txt file.\n",
            "CPU times: user 10.5 s, sys: 2.09 s, total: 12.6 s\n",
            "Wall time: 29.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import pandas as pd\n",
        "import itertools as it"
      ],
      "metadata": {
        "id": "9yYRUPI2052x"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7Pl02Eu1drE",
        "outputId": "14b04a99-4ebf-4732-9009-5b11a25621cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 21:12:59.871994: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_md')"
      ],
      "metadata": {
        "id": "8dd5N-2E07rv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_num = 42\n",
        "\n",
        "with open(review_txt_filepath) as f:\n",
        "    sample_review = list(it.islice(f, review_num, review_num+1))[0]\n",
        "    sample_review = sample_review.replace('\\\\n', '\\n')\n",
        "        \n",
        "print(sample_review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEmslJt112ck",
        "outputId": "87084e7c-538b-4b6f-d628-150ddb51292a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excellent service! Great diner food and breakfast is served all day. Came here for lunch- they were busy but very friendly and hospitable. Easy to get to off the 295.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "parsed_review = nlp(sample_review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxuOqRWc2Tn7",
        "outputId": "0c3c80bf-f6e7-470c-f9e1-0c1957d7bff5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 20.2 ms, sys: 4.03 ms, total: 24.2 ms\n",
            "Wall time: 35.8 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(parsed_review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9bBtStv2ZLk",
        "outputId": "ebee0dce-93ac-4f69-b98a-4faa17571a39"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excellent service! Great diner food and breakfast is served all day. Came here for lunch- they were busy but very friendly and hospitable. Easy to get to off the 295.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(parsed_review, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "l3DJVlZg2lMm",
        "outputId": "9327cbf4-03e8-4299-deff-726f2e9e91db"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Excellent service! Great diner food and breakfast is served \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    all day\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". Came here for lunch- they were busy but very friendly and hospitable. Easy to get to off the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    295\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              ".</br></div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from gensim.models.word2vec import LineSentence"
      ],
      "metadata": {
        "id": "8Ggq42Ch6BnG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def punct_space(token):\n",
        "    return token.is_punct or token.is_space\n",
        "\n",
        "def pronoun_lemmatize(token):\n",
        "    if token.lemma_ == '-PRON-':\n",
        "        return token.lower_\n",
        "    \n",
        "    else:\n",
        "        return token.lemma_.lower()\n",
        "\n",
        "def line_review(filename):\n",
        "    with open(filename) as f:\n",
        "        for review in f:\n",
        "            yield review.replace('\\\\n', '\\n')"
      ],
      "metadata": {
        "id": "fchScF996U-j"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_lemmatized_filepath = os.path.join(scratch_directory, 'review_lemmatized_all.txt')\n",
        "sentence_lemmatized_filepath = os.path.join(scratch_directory, 'sentence_lemmatized_all.txt')"
      ],
      "metadata": {
        "id": "BWmDFwDs6ovk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "execute = False\n",
        "\n",
        "if execute:\n",
        "    with open(review_lemmatized_filepath, 'w') as review_file:\n",
        "        with open(sentence_lemmatized_filepath, 'w') as sentence_file:\n",
        "            pipe = nlp.pipe(\n",
        "                line_review(review_txt_filepath),\n",
        "                batch_size=5000\n",
        "                )\n",
        "            \n",
        "            for parsed_review in pipe:\n",
        "                lemmatized_review = ' '.join([\n",
        "                    pronoun_lemmatize(token)\n",
        "                    for token in parsed_review\n",
        "                    if not punct_space(token)\n",
        "                    ])\n",
        "                \n",
        "                review_file.write(lemmatized_review + '\\n')\n",
        "        \n",
        "                for sent in parsed_review.sents:\n",
        "                    lemmatized_sentence = ' '.join([\n",
        "                        pronoun_lemmatize(token)\n",
        "                        for token in sent\n",
        "                        if not punct_space(token)\n",
        "                        ])\n",
        "                    \n",
        "                    sentence_file.write(lemmatized_sentence + '\\n')"
      ],
      "metadata": {
        "id": "0Vrh0J-M6vc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3928a1e-5015-446f-ad5b-3b7acb6dd7aa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 0 ns, sys: 5 µs, total: 5 µs\n",
            "Wall time: 9.3 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_unigrams = LineSentence(sentence_lemmatized_filepath)"
      ],
      "metadata": {
        "id": "2q7wDjjcgE4Z"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence_unigrams in it.islice(sentences_unigrams, 60, 70):\n",
        "    print(' '.join(sentence_unigrams))\n",
        "    print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07D4jzZQgHM3",
        "outputId": "409f3bd4-14a3-4aa1-8ca6-382bcb1550cc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bun make the sonoran dog\n",
            "\n",
            "it be like a snuggie for the pup\n",
            "\n",
            "a first it seem ridiculous and almost like it be go to be too much exactly like everyone 's favorite blanket with sleeve\n",
            "\n",
            "too much softness too much smush too indulgent\n",
            "\n",
            "wrong\n",
            "\n",
            "it be warm soft chewy fragrant and it succeed where other famed sonoran dogs fail\n",
            "\n",
            "the hot dog itself be flavorful but i would prefer that it or the bacon have a little more bite or snap to well hold their own against the dominant mustard and onion\n",
            "\n",
            "i be with the masse on the carne asada caramelo\n",
            "\n",
            "excellent tortilla salty melty cheese and great carne\n",
            "\n",
            "super cheap and you can drive through\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Por hacer**\n",
        "\n",
        "* Añadir comentarios\n",
        "* Incrustaciones de palabra con Word2vec\n",
        "* Visualizaciones\n",
        "* Modelado de frases\n",
        "* Limpieza de texto\n",
        "* Bigramas y trigramas\n",
        "* LDA\n",
        "* Álgebra de palabras"
      ],
      "metadata": {
        "id": "pq0aqfH1YqAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Referencias**\n",
        "\n",
        "* https://spacy.io/\n",
        "* https://radimrehurek.com/gensim/\n",
        "* https://github.com/pwharrison/modern-nlp-in-python-2019/blob/master/notebooks/Modern_NLP_in_Python.ipynb"
      ],
      "metadata": {
        "id": "QClEkJKWaKpp"
      }
    }
  ]
}