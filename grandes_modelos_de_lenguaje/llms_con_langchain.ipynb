{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoBRdgz/inteligencia_artificial/blob/main/grandes_modelos_de_lenguaje/llms_con_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introducción a LangChain\n",
        "\n",
        "LangChain es un marco para desarrollar aplicaciones impulsadas por modelos de lenguaje.\n",
        "\n",
        "**Objetivos** Revisión de los siguientes conceptos:\n",
        "\n",
        "- LLMs (Grandes modelos de lenguaje)\n",
        "- Prompt Templates (Plantillas)\n",
        "- Chains (Cadenas)\n",
        "- Agents and Tools (Agentes y herramientas)\n",
        "- Memory (Memoria)\n",
        "- Document Loaders (Cargadores de documentos)\n",
        "- Indexes (Índices)"
      ],
      "metadata": {
        "id": "nTDgRy0jKDkP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalación"
      ],
      "metadata": {
        "id": "5WGtOYYTKfz3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bcrn7QRyQXGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd858c24-6e6a-4c56-df64-9fe6ccb5e64d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.137-py3-none-any.whl (518 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.3/518.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from langchain) (6.0)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.22.4)\n",
            "Collecting async-timeout<5.0.0,>=4.0.0\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.9/dist-packages (from langchain) (2.27.1)\n",
            "Collecting SQLAlchemy<2,>=1\n",
            "  Downloading SQLAlchemy-1.4.47-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.10.7)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, openapi-schema-pydantic, marshmallow-enum, aiosignal, dataclasses-json, aiohttp, langchain\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.9\n",
            "    Uninstalling SQLAlchemy-2.0.9:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.9\n",
            "Successfully installed SQLAlchemy-1.4.47 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.7 frozenlist-1.3.3 langchain-0.0.137 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.8.0 yarl-1.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. LLMs\n",
        "\n",
        "Una interfaz genérica para todos los LLM. Ver todos los proveedores de LLM: https://python.langchain.com/en/latest/modules/models/llms/integrations.html"
      ],
      "metadata": {
        "id": "NkGGSdmtta6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys"
      ],
      "metadata": {
        "id": "o44cR-rCEQR9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Colab Notebooks/Inteligencia Artificial/Grandes Modelos de Lenguaje'"
      ],
      "metadata": {
        "id": "aHIw1WaiDz2n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnNEMiQ8ClME",
        "outputId": "86e404ac-2e69-4419-f9d4-37a89dd07d95"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append(path)"
      ],
      "metadata": {
        "id": "uSE3-5XrCrcr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "idkq_aVyaceF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17fe19f7-f418-470c-e6f0-3bacfd78fead"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (3.11.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub) (2.0.12)\n",
            "Installing collected packages: huggingface_hub\n",
            "Successfully installed huggingface_hub-0.13.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from config import api_key_hgface"
      ],
      "metadata": {
        "id": "bq4iPAj3S6fA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = api_key_hgface"
      ],
      "metadata": {
        "id": "i4DKOWjyaRmO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub"
      ],
      "metadata": {
        "id": "QmtH72oCaU32"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceHub(repo_id=\"google/flan-t5-xl\", model_kwargs={\"temperature\":0, \"max_length\":64})\n",
        "llm(\"Traducir de español a alemán: ¿Qué edad tienes?\")"
      ],
      "metadata": {
        "id": "8uK5TtJPc49I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1bee07c-6430-4bb7-ba22-68177854e87c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Was ist Ihr Alter?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "H_dfy6G_aBtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3323aaf4-af8a-45cf-ac8c-14f00ae4066d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from config import api_key_openai"
      ],
      "metadata": {
        "id": "RBMRc2L0EYMI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = api_key_openai"
      ],
      "metadata": {
        "id": "RlxEmS1CaM5v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9, model_name=\"text-davinci-003\")\n",
        "text = \"¿Cuál sería un buen nombre para una startup disruptiva que ofrece servicios basados en inteligencia artificial?\"\n",
        "print(llm(text))"
      ],
      "metadata": {
        "id": "pY09s9cmZ6nQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56fe500e-3ca2-4436-aa43-ffd69188b2ac"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "MindFlare AI.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Prompt Templates\n",
        "\n",
        "LangChain facilita la gestión y la rápida optimización.\n",
        "\n",
        "Normalmente, cuando usa un LLM en una aplicación, no está enviando la entrada del usuario directamente al LLM. En su lugar, debe tomar la entrada del usuario y construir un aviso, y solo luego enviarlo al LLM."
      ],
      "metadata": {
        "id": "3O-7dO1htdO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm(\"¿Puede Andrés Manuel López Obrador tener una conversación con Porfirio Díaz?\")"
      ],
      "metadata": {
        "id": "_FDS9IDRapOt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f59b85ec-26ce-41a7-dc18-b63c6ab020ac"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nNo, esto es imposible, ya que Porfirio Díaz murió en 1915 y Andrés Manuel López Obrador nació en 1953.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Question: ¿Puede Andrés Manuel López Obrador tener una conversación con Porfirio Díaz?\n",
        "\n",
        "Pensemos paso a paso.\n",
        "\n",
        "Respuesta: \"\"\"\n",
        "llm(prompt)"
      ],
      "metadata": {
        "id": "lB4W8dM1tPAY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f9711b7b-a6e0-4e8f-8cf3-17bc2ce5c683"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nNo, no es posible. Porfirio Díaz murió en 1915, mientras que Andrés Manuel López Obrador nació en 1953, lo que significa que hay una discrepancia de casi 40 años entre ambos. Además, en la actualidad, Porfirio Díaz no está vivo para tener una conversación con Andrés Manuel López Obrador.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"\"\"Pregunta: {pregunta}\n",
        "\n",
        "Pensemos paso a paso.\n",
        "\n",
        "Respuesta: \"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"pregunta\"])"
      ],
      "metadata": {
        "id": "UU1VyMMvtsCE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.format(pregunta=\"¿Puede Andrés Manuel López Obrador tener una conversación con Porfirio Díaz?\")"
      ],
      "metadata": {
        "id": "-Yzpc_0aHHeE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "866775e2-4c86-4520-e20f-f07e20e62010"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Pregunta: ¿Puede Andrés Manuel López Obrador tener una conversación con Porfirio Díaz?\\n\\nPensemos paso a paso.\\n\\nRespuesta: '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    llm(prompt)\n",
        "except Exception as e:\n",
        "    print(\"Requerimos de una cadena 'Chain'\")"
      ],
      "metadata": {
        "id": "on8ubh3kt7oD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "945e7cbd-5a7f-4352-b249-1db47afaf17f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requerimos de una cadena 'Chain'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Chains\n",
        "\n",
        "Combina LLM y prompts en flujos de trabajo de varios pasos."
      ],
      "metadata": {
        "id": "1zw1KlSeuUOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain"
      ],
      "metadata": {
        "id": "WNP4il5rT0NE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "question = \"¿Puede Andrés Manuel López Obrador tener una conversación con Porfirio Díaz?\"\n",
        "print(llm_chain.run(question))"
      ],
      "metadata": {
        "id": "eE6n-jbAuOxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6205245-5ee0-4743-9e22-821b6cc8cc7c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "No, Andrés Manuel López Obrador actualmente es el Presidente de México, mientras que Porfirio Díaz murió en 1915. Esto significa que no sería posible tener una conversación entre ellos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Agentes y Herramientas\n",
        "\n",
        "Los agentes involucran a un LLM que toma decisiones sobre qué acciones tomar, ejecutar esa acción, tener en cuenta una observación y repetirla hasta que se termine.\n",
        "\n",
        "Cuando se usan correctamente, los agentes pueden ser extremadamente poderosos.Para cargar agentes se deben comprender los siguientes conceptos:\n",
        "\n",
        "- Herramienta (tool): Función que realiza un deber específico. Esto puede ser por ejemplo: una búsqueda en Google, búsqueda en base de datos, Python REPL, entre otras cadenas.\n",
        "- LLM: El modelo de lenguaje que impulsa al agente.\n",
        "- Agente: El agente a utilizar."
      ],
      "metadata": {
        "id": "Zp-UlOK0bMVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "dOSpaurEb1MR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0361ac7f-1259-49cb-db2b-f9c69acf0192"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from wikipedia) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wikipedia) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.12)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->wikipedia) (2.4)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11696 sha256=2e2760e2bd7e329784f80413dc01d78d551a29cc3a15f2f1b936627a2b067696\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/46/f4/caa1bee71096d7b0cdca2f2a2af45cacf35c5760bee8f00948\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent"
      ],
      "metadata": {
        "id": "79JcjhFXwv0J"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)"
      ],
      "metadata": {
        "id": "RgV4kny1bgy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
      ],
      "metadata": {
        "id": "iQUOsWLrbjKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"¿En qué año se estrenó la película Inception con Leonardo Dicaprio? ¿Cuál sería este año elevado a la potencia 0,43?\")"
      ],
      "metadata": {
        "id": "M8Rob2Wsb_l9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "b50db39a-3a8d-47eb-f726-a7112a1e2bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out the year the movie was released and then use the calculator to calculate the power.\n",
            "Action: Wikipedia\n",
            "Action Input: Inception (2010 film)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: Inception\n",
            "Summary: Inception is a 2010 science fiction action film written and directed by Christopher Nolan, who also produced the film with Emma Thomas, his wife. The film stars Leonardo DiCaprio as a professional thief who steals information by infiltrating the subconscious of his targets. He is offered a chance to have his criminal history erased as payment for the implantation of another person's idea into a target's subconscious. The ensemble cast includes Ken Watanabe, Joseph Gordon-Levitt, Marion Cotillard, Elliot Page, Tom Hardy, Dileep Rao, Cillian Murphy, Tom Berenger, and Michael Caine.\n",
            "After the 2002 completion of Insomnia, Nolan presented to Warner Bros. a written 80-page treatment for a horror film envisioning \"dream stealers,\" based on lucid dreaming. Deciding he needed more experience before tackling a production of this magnitude and complexity, Nolan shelved the project and instead worked on 2005's Batman Begins, 2006's The Prestige, and The Dark Knight in 2008. The treatment was revised over 6 months and was purchased by Warner in February 2009. Inception was filmed in six countries, beginning in Tokyo on June 19 and ending in Canada on November 22. Its official budget was $160 million, split between Warner Bros. and Legendary. Nolan's reputation and success with The Dark Knight helped secure the film's US$100 million in advertising expenditure.\n",
            "Inception's premiere was held in London on July 8, 2010; it was released in both conventional and IMAX theaters beginning on July 16, 2010. Inception grossed over $828 million worldwide, becoming the fourth-highest-grossing film of 2010. Considered one of the best films of the 2010s, Inception won four Academy Awards (Best Cinematography, Best Sound Editing, Best Sound Mixing, and Best Visual Effects) and was nominated for four more: Best Picture, Best Original Screenplay, Best Art Direction, and Best Original Score.\n",
            "\n",
            "Page: Inception (soundtrack)\n",
            "Summary: Inception: Music from the Motion Picture is the soundtrack to the 2010 film of the same name directed by Christopher Nolan, released under Reprise Records on July 13, 2010. Hans Zimmer scored the film, marking his third collaboration with Nolan following Batman Begins and The Dark Knight.\n",
            "\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the year the movie was released.\n",
            "Action: Calculator\n",
            "Action Input: 2010^0.43\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 26.3253591394933\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: El año 2010 elevado a la potencia 0,43 es 26.3253591394933.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'El año 2010 elevado a la potencia 0,43 es 26.3253591394933.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Memoria\n",
        "\n",
        "Agregar Estado a Cadenas y Agentes.\n",
        "\n",
        "La memoria es el concepto de estado persistente entre llamadas de una cadena/agente. LangChain proporciona una interfaz estándar para la memoria, una colección de implementaciones de memoria y ejemplos de cadenas/agentes que usan memoria."
      ],
      "metadata": {
        "id": "8AuQNfhYm48A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, ConversationChain"
      ],
      "metadata": {
        "id": "tPaPubGMKZpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)\n",
        "conversation = ConversationChain(llm=llm, verbose=True)\n",
        "\n",
        "conversation.predict(input=\"Hola!\")"
      ],
      "metadata": {
        "id": "Ujwj29G2cDPN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "82de0ac2-2060-432b-b53d-88d464798240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hola!\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Hola! ¿Cómo estás? Me llamo AI. ¿Cómo te llamas?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"¿Podemos hablar de IA?\")"
      ],
      "metadata": {
        "id": "XkKv8n7ZnB2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "8649fa2a-f150-4913-8c11-7882ea342359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hola!\n",
            "AI:  Hola! ¿Cómo estás? Me llamo AI. ¿Cómo te llamas?\n",
            "Human: ¿Podemos hablar de IA?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' ¡Claro! ¿Qué quieres saber sobre Inteligencia Artificial?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Estoy interesado en la inteligencia artificial general\")"
      ],
      "metadata": {
        "id": "r4P3zWCmoDST",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "671fe4f2-46d6-4922-a33e-c1820a9c04c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hola!\n",
            "AI:  Hola! ¿Cómo estás? Me llamo AI. ¿Cómo te llamas?\n",
            "Human: ¿Podemos hablar de IA?\n",
            "AI:  ¡Claro! ¿Qué quieres saber sobre Inteligencia Artificial?\n",
            "Human: Estoy interesado en la inteligencia artificial general\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' La Inteligencia Artificial General se refiere a la creación de sistemas informáticos que pueden realizar tareas inteligentes sin necesidad de programación específica. Estos sistemas pueden aprender, planificar, razonar, entender el lenguaje y tomar decisiones.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Cargadores de documentos\n",
        "\n",
        "La combinación de modelos de lenguaje con sus propios datos de texto es una forma poderosa de diferenciarlos. El primer paso para hacer esto es cargar los datos en \"documentos\", una forma elegante de decir algunos fragmentos de texto. Este módulo tiene como objetivo hacer esto fácil.\n",
        "\n",
        "https://python.langchain.com/en/latest/modules/indexes/document_loaders.html"
      ],
      "metadata": {
        "id": "9wMttXM-CuPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured\n",
        "!pip install unstructured[local-inference]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TYZOtVGUzFVy",
        "outputId": "e5e54bbb-5629-4185-978d-4e3ae89d0f34"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.9/dist-packages (0.5.11)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from unstructured) (8.4.0)\n",
            "Requirement already satisfied: msg-parser in /usr/local/lib/python3.9/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.9/dist-packages (from unstructured) (3.4.3)\n",
            "Requirement already satisfied: certifi>=2022.12.07 in /usr/local/lib/python3.9/dist-packages (from unstructured) (2022.12.7)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.9/dist-packages (from unstructured) (0.6.21)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.9/dist-packages (from unstructured) (3.0.10)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from unstructured) (4.9.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from unstructured) (1.5.3)\n",
            "Requirement already satisfied: argilla in /usr/local/lib/python3.9/dist-packages (from unstructured) (1.6.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.9/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.9/dist-packages (from unstructured) (1.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from unstructured) (2.27.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.9/dist-packages (from unstructured) (0.8.11)\n",
            "Requirement already satisfied: numpy<1.24.0 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (1.22.4)\n",
            "Requirement already satisfied: monotonic in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (1.6)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (2.2.1)\n",
            "Requirement already satisfied: rich<=13.0.1 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (13.0.1)\n",
            "Requirement already satisfied: deprecated~=1.2.0 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (1.2.13)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.13 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (1.14.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (4.65.0)\n",
            "Requirement already satisfied: httpx<0.24,>=0.15 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (0.23.3)\n",
            "Requirement already satisfied: pydantic>=1.7.1 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (1.10.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->unstructured) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->unstructured) (2022.7.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown->unstructured) (6.2.0)\n",
            "Requirement already satisfied: olefile>=0.46 in /usr/local/lib/python3.9/dist-packages (from msg-parser->unstructured) (0.46)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->unstructured) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->unstructured) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->unstructured) (1.2.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.9/dist-packages (from openpyxl->unstructured) (1.1.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.9/dist-packages (from python-pptx->unstructured) (3.0.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->unstructured) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->unstructured) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->unstructured) (1.26.15)\n",
            "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /usr/local/lib/python3.9/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (0.16.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.3.0)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.9/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown->unstructured) (3.15.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic>=1.7.1->argilla->unstructured) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->unstructured) (1.16.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from rich<=13.0.1->argilla->unstructured) (2.14.0)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from rich<=13.0.1->argilla->unstructured) (0.9.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.9/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (0.14.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.9/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (3.6.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: unstructured[local-inference] in /usr/local/lib/python3.9/dist-packages (0.5.11)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from unstructured[local-inference]) (3.8.1)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.9/dist-packages (from unstructured[local-inference]) (0.6.21)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.9/dist-packages (from unstructured[local-inference]) (3.4.3)\n",
            "Requirement already satisfied: certifi>=2022.12.07 in /usr/local/lib/python3.9/dist-packages (from unstructured[local-inference]) (2022.12.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from unstructured[local-inference]) (2.27.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from unstructured[local-inference]) (8.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from unstructured[local-inference]) (4.9.2)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.9/dist-packages (from unstructured[local-inference]) (0.8.11)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.9/dist-packages (from unstructured[local-inference]) (3.0.10)\n",
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.9/dist-packages (from unstructured[local-inference]) (1.11)\n",
            "Requirement already satisfied: msg-parser in /usr/local/lib/python3.9/dist-packages (from unstructured[local-inference]) (1.2.0)\n",
            "Requirement already satisfied: argilla in /usr/local/lib/python3.9/dist-packages (from unstructured[local-inference]) (1.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from unstructured[local-inference]) (1.5.3)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.9/dist-packages (from unstructured[local-inference]) (0.4.27)\n",
            "Collecting unstructured-inference==0.3.2\n",
            "  Downloading unstructured_inference-0.3.2.tar.gz (31 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.95.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting layoutparser[layoutmodels,tesseract]\n",
            "  Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from unstructured-inference==0.3.2->unstructured[local-inference]) (0.13.4)\n",
            "Collecting opencv-python==4.6.0.66\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime\n",
            "  Downloading onnxruntime-1.14.1-cp39-cp39-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.9/dist-packages (from opencv-python==4.6.0.66->unstructured-inference==0.3.2->unstructured[local-inference]) (1.22.4)\n",
            "Requirement already satisfied: monotonic in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured[local-inference]) (1.6)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured[local-inference]) (4.65.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.13 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured[local-inference]) (1.14.1)\n",
            "Requirement already satisfied: rich<=13.0.1 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured[local-inference]) (13.0.1)\n",
            "Requirement already satisfied: httpx<0.24,>=0.15 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured[local-inference]) (0.23.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured[local-inference]) (23.0)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured[local-inference]) (2.2.1)\n",
            "Requirement already satisfied: pydantic>=1.7.1 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured[local-inference]) (1.10.7)\n",
            "Requirement already satisfied: deprecated~=1.2.0 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured[local-inference]) (1.2.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->unstructured[local-inference]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->unstructured[local-inference]) (2022.7.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown->unstructured[local-inference]) (6.2.0)\n",
            "Requirement already satisfied: olefile>=0.46 in /usr/local/lib/python3.9/dist-packages (from msg-parser->unstructured[local-inference]) (0.46)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->unstructured[local-inference]) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->unstructured[local-inference]) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->unstructured[local-inference]) (8.1.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.9/dist-packages (from openpyxl->unstructured[local-inference]) (1.1.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.9/dist-packages (from python-pptx->unstructured[local-inference]) (3.0.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->unstructured[local-inference]) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->unstructured[local-inference]) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->unstructured[local-inference]) (2.0.12)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.9/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured[local-inference]) (1.5.0)\n",
            "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /usr/local/lib/python3.9/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured[local-inference]) (0.16.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured[local-inference]) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown->unstructured[local-inference]) (3.15.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic>=1.7.1->argilla->unstructured[local-inference]) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->unstructured[local-inference]) (1.16.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from rich<=13.0.1->argilla->unstructured[local-inference]) (2.14.0)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from rich<=13.0.1->argilla->unstructured[local-inference]) (0.9.1)\n",
            "Collecting starlette<0.27.0,>=0.26.1\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->unstructured-inference==0.3.2->unstructured[local-inference]) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->unstructured-inference==0.3.2->unstructured[local-inference]) (3.11.0)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.8.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (1.10.1)\n",
            "Collecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Collecting effdet\n",
            "  Downloading effdet-0.3.0-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (0.15.1+cu118)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime->unstructured-inference==0.3.2->unstructured[local-inference]) (1.11.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime->unstructured-inference==0.3.2->unstructured[local-inference]) (23.3.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnxruntime->unstructured-inference==0.3.2->unstructured[local-inference]) (3.20.3)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.9/dist-packages (from uvicorn->unstructured-inference==0.3.2->unstructured[local-inference]) (0.14.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.9/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured[local-inference]) (3.6.2)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (2.0.6)\n",
            "Collecting timm>=0.4.12\n",
            "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf>=2.0\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (16.0.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting pdfminer.six==20221105\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Wand>=0.6.10\n",
            "  Downloading Wand-0.6.11-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.6/143.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow\n",
            "  Downloading Pillow-9.5.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.9/dist-packages (from pdfminer.six==20221105->pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (40.0.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime->unstructured-inference==0.3.2->unstructured[local-inference]) (1.3.0)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (3.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (2.1.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (1.15.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (4.39.3)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (5.12.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2->unstructured[local-inference]) (2.21)\n",
            "Building wheels for collected packages: unstructured-inference, iopath, antlr4-python3-runtime\n",
            "  Building wheel for unstructured-inference (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unstructured-inference: filename=unstructured_inference-0.3.2-py3-none-any.whl size=33506 sha256=ee2f102e5defc3227b8567a480607bff30c96c64576c9fb0d2c87b5d7365e796\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/e1/fa/ba42c58d1a92c07799d65196bb47bb7a6f9ae2f51cbf5388f5\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=c7d3c76b65cf5b80482423210b45e23c9ea8cc5980e7c4674330c0127a429f71\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/13/6d/441d8f2af76ee6d2a3e67eebb1d0c556fefcee0a8b32266a8e\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144573 sha256=31a857d01ec037c19897179c3416b4411784b5dde88af18a8b7bd60f2c80c8d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n",
            "Successfully built unstructured-inference iopath antlr4-python3-runtime\n",
            "Installing collected packages: Wand, tokenizers, antlr4-python3-runtime, uvicorn, python-multipart, portalocker, pillow, opencv-python, omegaconf, humanfriendly, starlette, pytesseract, pdf2image, iopath, coloredlogs, transformers, pdfminer.six, onnxruntime, fastapi, pdfplumber, layoutparser, timm, effdet, unstructured-inference\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.7.0.72\n",
            "    Uninstalling opencv-python-4.7.0.72:\n",
            "      Successfully uninstalled opencv-python-4.7.0.72\n",
            "Successfully installed Wand-0.6.11 antlr4-python3-runtime-4.9.3 coloredlogs-15.0.1 effdet-0.3.0 fastapi-0.95.0 humanfriendly-10.0 iopath-0.1.10 layoutparser-0.3.4 omegaconf-2.3.0 onnxruntime-1.14.1 opencv-python-4.6.0.66 pdf2image-1.16.3 pdfminer.six-20221105 pdfplumber-0.8.1 pillow-9.5.0 portalocker-2.7.0 pytesseract-0.3.10 python-multipart-0.0.6 starlette-0.26.1 timm-0.6.13 tokenizers-0.13.3 transformers-4.27.4 unstructured-inference-0.3.2 uvicorn-0.21.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import OnlinePDFLoader"
      ],
      "metadata": {
        "id": "dIcXQn1_Kdy2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = OnlinePDFLoader(\"https://arxiv.org/pdf/1706.03762.pdf\")\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "iAiISOcboPKR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cea4ac6-f1c0-42d8-a40c-a8f9be96f084"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:unstructured:detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (f'Existen {len(data)} documento (s) en el archivo')\n",
        "print (f'Hay {len(data[0].page_content)} caracteres en el documento')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZnqxgnI0WMM",
        "outputId": "e953bd1d-478a-4b0f-938f-6d3b3976e29c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existen 1 documento (s) en el archivo\n",
            "Hay 39933 caracteres en el documento\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Índices\n",
        "\n",
        "Los índices se refieren a formas de estructurar documentos para que los LLM puedan interactuar mejor con ellos. Este módulo contiene funciones de utilidad para trabajar con documentos.\n",
        "\n",
        "- Incrustaciones: Una incrustación es una representación numérica de una información, por ejemplo, texto, documentos, imágenes, audio, etc.\n",
        "- Divisores de texto: Cuando desee manejar fragmentos largos de texto, es necesario dividir ese texto en fragmentos.\n",
        "- Almacenes de vectores: Las bases de datos vectoriales almacenan e indexan incrustaciones de vectores de modelos NLP para comprender el significado y el contexto de cadenas de texto, oraciones y documentos completos para obtener resultados de búsqueda más precisos y relevantes."
      ],
      "metadata": {
        "id": "Cwlwe_iWKucO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/hwchase17/langchain/master/docs/modules/state_of_the_union.txt\"\n",
        "res = requests.get(url)\n",
        "with open(\"state_of_the_union.txt\", \"w\") as f:\n",
        "    f.write(res.text)"
      ],
      "metadata": {
        "id": "qLU79cyCozYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader"
      ],
      "metadata": {
        "id": "KkSlw3uuLA9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = TextLoader('./state_of_the_union.txt')\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "XGyZXiJZBsov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "gqLFKKHULDJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "OklI0xTvp2KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "skvXSMXHCxyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "JExaota0LO_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings()\n",
        "\n",
        "#text = \"This is a test document.\"\n",
        "#query_result = embeddings.embed_query(text)\n",
        "#doc_result = embeddings.embed_documents([text])"
      ],
      "metadata": {
        "id": "V1yCdAhSCi64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "8R3pT55b-uBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Almacen de vectores: https://python.langchain.com/en/latest/modules/indexes/vectorstores.html\n",
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "GOaY0V9bLfOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "docs = db.similarity_search(query)"
      ],
      "metadata": {
        "id": "W7sRydnlC7rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB7lvDWzDHZy",
        "outputId": "5d8794b8-929a-4a31-cf6e-a158fbaba9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
            "\n",
            "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
            "\n",
            "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
            "\n",
            "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db.save_local(\"faiss_index\")\n",
        "new_db = FAISS.load_local(\"faiss_index\", embeddings)\n",
        "docs = new_db.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "id": "nu-AmhDLEK0h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80bc4e26-f90e-45dd-bd45-45ef3d23998a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
            "\n",
            "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
            "\n",
            "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
            "\n",
            "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Por hacer**\n",
        "\n",
        "* Probar el último ejemplo con alguna lectura en español"
      ],
      "metadata": {
        "id": "eaHhp5etL0ub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Referencias**\n",
        "\n",
        "* https://github.com/hwchase17/langchain\n",
        "* https://huggingface.co/google/flan-t5-xl\n",
        "* https://python.langchain.com/en/latest/index.html\n",
        "* https://python.langchain.com/en/latest/modules/agents/tools.html\n",
        "* https://python.langchain.com/en/latest/modules/agents/agents/agent_types.html\n"
      ],
      "metadata": {
        "id": "7oSLo6kU6z0G"
      }
    }
  ]
}