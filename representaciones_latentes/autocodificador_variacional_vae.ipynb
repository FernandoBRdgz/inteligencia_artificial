{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPx/Y5/DYMTqAWAfTCibKII",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoBRdgz/inteligencia_artificial/blob/main/representaciones_latentes/autocodificador_variacional_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducción\n",
        "\n",
        "Este *notebook* muestra como construir un autocodificador variacional, mejor conocido como Variational Autoencoder (VAE) entrenando un modelo en el conjunto de datos MNIST para generar nuevas imágenes.\n",
        "\n",
        "Un autocodificador variacional es un modelo generativo basado en probabilidad. Consiste en un codificador, que toma datos x como entrada y los transforma en una representación latente z, y un decodificador, que toma una representación latente z y devuelve una reconstrucción y. La inferencia se realiza a través de la inferencia variacional para aproximar la parte posterior del modelo."
      ],
      "metadata": {
        "id": "H3X_nrDZfHST"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RC4jB-5Je91Y"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "latent_dim = 2"
      ],
      "metadata": {
        "id": "0udU8tWrgNie"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_image(image, label):\n",
        "    image = tf.cast(image, dtype=tf.float32)\n",
        "    image /= 255.0\n",
        "    image = tf.reshape(image, shape=(28,28,1,))\n",
        "    return image\n",
        "\n",
        "def get_dataset(map_fn, is_validation=False):\n",
        "    if is_validation:\n",
        "        split_name = \"test\"\n",
        "    else:\n",
        "        split_name = \"train\"\n",
        "  \n",
        "    dataset = tfds.load(\"mnist\", as_supervised=True, split=split_name)\n",
        "    dataset = dataset.map(map_fn)\n",
        "\n",
        "    if is_validation:\n",
        "        dataset = dataset.batch(batch_size)\n",
        "    else:\n",
        "        dataset = dataset.shuffle(1024).batch(batch_size)\n",
        "  \n",
        "    return dataset"
      ],
      "metadata": {
        "id": "hsnMnFIbgVGE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = get_dataset(map_image)"
      ],
      "metadata": {
        "id": "WerA8xGTgXwC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(tf.keras.layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    mu, sigma = inputs\n",
        "\n",
        "    batch = tf.shape(mu)[0]\n",
        "    dim = tf.shape(mu)[1]\n",
        "\n",
        "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "\n",
        "    return mu + tf.exp(0.5 * sigma) * epsilon"
      ],
      "metadata": {
        "id": "vTQaVFChgZ1H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_layers(inputs, latent_dim):\n",
        "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\", name=\"encode_conv1\")(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\", name=\"encoder_conv2\")(x)\n",
        "\n",
        "    batch_2 = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x = tf.keras.layers.Flatten(name=\"encode_flatten\")(batch_2)\n",
        "\n",
        "    x = tf.keras.layers.Dense(20, activation=\"relu\", name=\"encoder_dense\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    mu = tf.keras.layers.Dense(latent_dim, name=\"latent_mu\")(x)\n",
        "    sigma = tf.keras.layers.Dense(latent_dim, name=\"latent_sigma\")(x)\n",
        "\n",
        "    return mu, sigma, batch_2.shape"
      ],
      "metadata": {
        "id": "Zeub40m7gqWp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_model(latent_dim, input_shape):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "    mu, sigma, conv_shape = encoder_layers(inputs, latent_dim=latent_dim)\n",
        "    z = Sampling()((mu, sigma))\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=[mu, sigma, z])\n",
        "\n",
        "    return model, conv_shape"
      ],
      "metadata": {
        "id": "umFqRJO0g1Jb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Por hacer**\n",
        "\n",
        "* Descripción del modelo VAE\n",
        "* Decodificador\n",
        "* Función de costo\n",
        "* Entrenamiento de modelo\n",
        "* Predicciones\n",
        "* Comentar funciones\n",
        "* Referencia\n"
      ],
      "metadata": {
        "id": "uY_ErMhKhBQc"
      }
    }
  ]
}