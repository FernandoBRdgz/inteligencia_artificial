{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsdelOvoJRc8i2AHAHyXIv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "edeb9cae57b44ab88b9690fc8f6ed352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e43055a3fff463abbe6ff6ce86faa56",
              "IPY_MODEL_e5c5f5573e664221b0b513da8c4093d5",
              "IPY_MODEL_54342c220d694ed8887a43264ca1d8cb"
            ],
            "layout": "IPY_MODEL_46293f947af7486894630c546848b1d8"
          }
        },
        "6e43055a3fff463abbe6ff6ce86faa56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c9b60db4d9143a7b984a252080a044f",
            "placeholder": "​",
            "style": "IPY_MODEL_eb2b0a730a594e52ba2b383005b4f909",
            "value": "Dl Completed...: 100%"
          }
        },
        "e5c5f5573e664221b0b513da8c4093d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cebf4ab3711042d18993af85173da1b1",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b07601f1986e46dcb1bd90f4320e650e",
            "value": 5
          }
        },
        "54342c220d694ed8887a43264ca1d8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8125423b938e4218b44331cc169cca4f",
            "placeholder": "​",
            "style": "IPY_MODEL_6b934f382e3a4f4da898b7b49a25735c",
            "value": " 5/5 [00:03&lt;00:00,  1.08 file/s]"
          }
        },
        "46293f947af7486894630c546848b1d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c9b60db4d9143a7b984a252080a044f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb2b0a730a594e52ba2b383005b4f909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cebf4ab3711042d18993af85173da1b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b07601f1986e46dcb1bd90f4320e650e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8125423b938e4218b44331cc169cca4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b934f382e3a4f4da898b7b49a25735c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoBRdgz/inteligencia_artificial/blob/main/representaciones_latentes/autocodificador_variacional_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducción\n",
        "\n",
        "Este *notebook* muestra como construir un autocodificador variacional, mejor conocido como Variational Autoencoder (VAE) entrenando un modelo en el conjunto de datos MNIST para generar nuevas imágenes.\n",
        "\n",
        "Un autocodificador variacional es un modelo generativo basado en probabilidad. Consiste en un codificador, que toma datos x como entrada y los transforma en una representación latente z, y un decodificador, que toma una representación latente z y devuelve una reconstrucción y. La inferencia se realiza a través de la inferencia variacional para aproximar la parte posterior del modelo."
      ],
      "metadata": {
        "id": "H3X_nrDZfHST"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RC4jB-5Je91Y"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "latent_dim = 2"
      ],
      "metadata": {
        "id": "0udU8tWrgNie"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_image(image, label):\n",
        "    image = tf.cast(image, dtype=tf.float32)\n",
        "    image /= 255.0\n",
        "    image = tf.reshape(image, shape=(28,28,1,))\n",
        "    return image"
      ],
      "metadata": {
        "id": "rQal3vwbUmTG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(map_fn, is_validation=False):\n",
        "    if is_validation:\n",
        "        split_name = \"test\"\n",
        "    else:\n",
        "        split_name = \"train\"\n",
        "  \n",
        "    dataset = tfds.load(\"mnist\", as_supervised=True, split=split_name)\n",
        "    dataset = dataset.map(map_fn)\n",
        "\n",
        "    if is_validation:\n",
        "        dataset = dataset.batch(batch_size)\n",
        "    else:\n",
        "        dataset = dataset.shuffle(1024).batch(batch_size)\n",
        "  \n",
        "    return dataset"
      ],
      "metadata": {
        "id": "hsnMnFIbgVGE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = get_dataset(map_image, is_validation=False)\n",
        "val_dataset = get_dataset(map_image, is_validation=True)"
      ],
      "metadata": {
        "id": "WerA8xGTgXwC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "edeb9cae57b44ab88b9690fc8f6ed352",
            "6e43055a3fff463abbe6ff6ce86faa56",
            "e5c5f5573e664221b0b513da8c4093d5",
            "54342c220d694ed8887a43264ca1d8cb",
            "46293f947af7486894630c546848b1d8",
            "5c9b60db4d9143a7b984a252080a044f",
            "eb2b0a730a594e52ba2b383005b4f909",
            "cebf4ab3711042d18993af85173da1b1",
            "b07601f1986e46dcb1bd90f4320e650e",
            "8125423b938e4218b44331cc169cca4f",
            "6b934f382e3a4f4da898b7b49a25735c"
          ]
        },
        "outputId": "d35c6a7b-1877-4615-f1e5-d3574f34166a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/mnist/3.0.1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edeb9cae57b44ab88b9690fc8f6ed352"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensiones del primer lote\n",
        "list(train_dataset.as_numpy_iterator())[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdZFLry1XJWJ",
        "outputId": "33963768-0862-4857-bbf1-5bd871e4d507"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Imagen del primer lote\n",
        " plt.imshow(list(train_dataset.as_numpy_iterator())[0][0], cmap=\"gray\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "WhQWMqg-Zw9_",
        "outputId": "350bd2d8-d09a-41e0-ac8e-88e5bbd6ed24"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Codificador"
      ],
      "metadata": {
        "id": "NZI1wRdTWnKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        mu, sigma = inputs\n",
        "\n",
        "        batch = tf.shape(mu)[0]\n",
        "        dim = tf.shape(mu)[1]\n",
        "\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "\n",
        "        return mu + tf.exp(0.5 * sigma) * epsilon"
      ],
      "metadata": {
        "id": "vTQaVFChgZ1H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_layers(inputs, latent_dim):\n",
        "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\", name=\"encode_conv1\")(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\", name=\"encoder_conv2\")(x)\n",
        "\n",
        "    batch_2 = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x = tf.keras.layers.Flatten(name=\"encode_flatten\")(batch_2)\n",
        "    x = tf.keras.layers.Dense(20, activation=\"relu\", name=\"encoder_dense\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    mu = tf.keras.layers.Dense(latent_dim, name=\"latent_mu\")(x)\n",
        "    sigma = tf.keras.layers.Dense(latent_dim, name=\"latent_sigma\")(x)\n",
        "\n",
        "    return mu, sigma, batch_2.shape"
      ],
      "metadata": {
        "id": "Zeub40m7gqWp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_model(latent_dim, input_shape):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "    mu, sigma, conv_shape = encoder_layers(inputs, latent_dim=latent_dim)\n",
        "    z = Sampling()((mu, sigma))\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=[mu, sigma, z])\n",
        "\n",
        "    return model, conv_shape"
      ],
      "metadata": {
        "id": "umFqRJO0g1Jb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decodificador"
      ],
      "metadata": {
        "id": "etIgq2ryWpfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_layers(inputs, conv_shape):\n",
        "    units = conv_shape[1] * conv_shape[2] * conv_shape[3]\n",
        "    x = tf.keras.layers.Dense(units, activation=\"relu\", name=\"decode_dense1\")(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Reshape((conv_shape[1], conv_shape[2], conv_shape[3]), name=\"decode_reshape\")(x)\n",
        "    x = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\", name=\"decode_conv2d_2\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\", name=\"decode_conv2d_3\")(x)\n",
        "    x =tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding=\"same\", activation=\"sigmoid\", name=\"decode_final\")(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "fcJdxv2mWrWS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_model(latent_dim, conv_shape):\n",
        "    inputs = tf.keras.layers.Input(shape=(latent_dim,))\n",
        "    outputs = decoder_layers(inputs, conv_shape)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "dr07QXdsW7vV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kl_reconstruction_loss(inputs, outputs, mu, sigma):\n",
        "    kl_loss = 1 + sigma - tf.square(mu) - tf.math.exp(sigma)\n",
        "    kl_loss = tf.reduce_mean(kl_loss) * - 0.5\n",
        "\n",
        "    return kl_loss"
      ],
      "metadata": {
        "id": "oS1ZZLHqkdGq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_model(encoder, decoder, input_shape):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    mu, sigma, z = encoder(inputs)\n",
        "    reconstructed = decoder(z)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=reconstructed)\n",
        "    loss = kl_reconstruction_loss(inputs, z, mu, sigma)\n",
        "    model.add_loss(loss)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "mb9T6wXxkpZa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_models(input_shape, latent_dim):\n",
        "    encoder, conv_shape = encoder_model(latent_dim=latent_dim, input_shape=input_shape)\n",
        "    decoder = decoder_model(latent_dim=latent_dim, conv_shape=conv_shape)\n",
        "    vae = vae_model(encoder, decoder, input_shape=input_shape)\n",
        "    return encoder, decoder, vae"
      ],
      "metadata": {
        "id": "fENNd7URkpUC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder, decoder, vae = get_models(input_shape=(28,28,1,), latent_dim=latent_dim)"
      ],
      "metadata": {
        "id": "d4uEcMKnk8Nq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-E73arclcL8",
        "outputId": "1b9ad553-6435-490f-8d47-324ebfe17acf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " encode_conv1 (Conv2D)          (None, 14, 14, 32)   320         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 14, 14, 32)  128         ['encode_conv1[0][0]']           \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " encoder_conv2 (Conv2D)         (None, 7, 7, 64)     18496       ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 7, 7, 64)    256         ['encoder_conv2[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " encode_flatten (Flatten)       (None, 3136)         0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " encoder_dense (Dense)          (None, 20)           62740       ['encode_flatten[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 20)          80          ['encoder_dense[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " latent_mu (Dense)              (None, 2)            42          ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " latent_sigma (Dense)           (None, 2)            42          ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " sampling (Sampling)            (None, 2)            0           ['latent_mu[0][0]',              \n",
            "                                                                  'latent_sigma[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 82,104\n",
            "Trainable params: 81,872\n",
            "Non-trainable params: 232\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdQjgRQGlg5I",
        "outputId": "89bcf36d-5330-4cc7-d980-3fa8e6fd91ef"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " decode_dense1 (Dense)       (None, 3136)              9408      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 3136)             12544     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " decode_reshape (Reshape)    (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " decode_conv2d_2 (Conv2DTran  (None, 14, 14, 64)       36928     \n",
            " spose)                                                          \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " decode_conv2d_3 (Conv2DTran  (None, 28, 28, 32)       18464     \n",
            " spose)                                                          \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 28, 28, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " decode_final (Conv2DTranspo  (None, 28, 28, 1)        289       \n",
            " se)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 78,017\n",
            "Trainable params: 71,553\n",
            "Non-trainable params: 6,464\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vae.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khTfhrpjlg1n",
        "outputId": "0adcdaed-2a4d-4823-8fe2-d05b32e6155d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " model (Functional)             [(None, 2),          82104       ['input_3[0][0]']                \n",
            "                                 (None, 2),                                                       \n",
            "                                 (None, 2)]                                                       \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, 28, 28, 1)    78017       ['model[0][2]']                  \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 2)           0           ['model[0][1]']                  \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.square (TFOpLambda)    (None, 2)            0           ['model[0][0]']                  \n",
            "                                                                                                  \n",
            " tf.math.subtract (TFOpLambda)  (None, 2)            0           ['tf.__operators__.add[0][0]',   \n",
            "                                                                  'tf.math.square[0][0]']         \n",
            "                                                                                                  \n",
            " tf.math.exp (TFOpLambda)       (None, 2)            0           ['model[0][1]']                  \n",
            "                                                                                                  \n",
            " tf.math.subtract_1 (TFOpLambda  (None, 2)           0           ['tf.math.subtract[0][0]',       \n",
            " )                                                                'tf.math.exp[0][0]']            \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean (TFOpLambd  ()                  0           ['tf.math.subtract_1[0][0]']     \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  ()                   0           ['tf.math.reduce_mean[0][0]']    \n",
            "                                                                                                  \n",
            " add_loss (AddLoss)             ()                   0           ['tf.math.multiply[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 160,121\n",
            "Trainable params: 153,425\n",
            "Non-trainable params: 6,696\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Por hacer**\n",
        "\n",
        "* Descripción del modelo VAE\n",
        "* Entrenamiento de modelo\n",
        "* Predicciones\n",
        "* Comentar funciones\n",
        "* Referencia\n"
      ],
      "metadata": {
        "id": "uY_ErMhKhBQc"
      }
    }
  ]
}